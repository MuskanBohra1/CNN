{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Project Report: Image Classification Using Convolutional Neural Networks  (CNN)**\n",
        "**Contributors**- **1.Himanshi Sharma.**(055012)\n",
        "                  **2.Muskan Bohra**(055025)\n",
        "\n",
        "### **1. Introduction**\n",
        "\n",
        "This project demonstrates the implementation of a Convolutional Neural Network (CNN) using TensorFlow and Keras for image classification. CNNs are widely used in image and video recognition, recommender systems, and natural language processing due to their high performance in visual recognition tasks.\n",
        "\n",
        "### **2. Objective**\n",
        "\n",
        "The main objective of this project is to build and train a CNN model capable of classifying images into appropriate categories. The model should learn to extract and identify important features from images to make accurate predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Dataset Description**\n",
        "\n",
        "The dataset used in the project appears to be an image dataset loaded using the `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`. Although the specific dataset name is not mentioned, based on the code, it's structured in a typical format where images are organized into folders corresponding to their class labels.\n",
        "\n",
        "**Key properties of the dataset:**\n",
        "\n",
        "- Divided into training and testing sets.\n",
        "- Images are resized to 64x64 pixels.\n",
        "- Batch size is set to 32.\n",
        "- Image rescaling is done to normalize the pixel values (0-255 scaled to 0-1).\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Data Preprocessing**\n",
        "\n",
        "The data preprocessing steps include:\n",
        "\n",
        "- **Rescaling** the pixel values to a range of [0,1] using `rescale=1./255`.\n",
        "- **Target size** set to (64, 64) for all images.\n",
        "- **Batch size**: 32\n",
        "- **Shuffling** is enabled for the training data.\n",
        "\n",
        "Code snippet used:\n",
        "\n",
        "```python\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('train', target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "test_set = test_datagen.flow_from_directory('test', target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. CNN Model Architecture**\n",
        "\n",
        "The model is built using the Sequential API of Keras. Here's the architecture used:\n",
        "\n",
        "1. **Convolutional Layer 1**\n",
        "   - Filters: 32\n",
        "   - Kernel size: (3,3)\n",
        "   - Activation: ReLU\n",
        "   - Input shape: (64, 64, 3)\n",
        "\n",
        "2. **MaxPooling Layer 1**\n",
        "   - Pool size: (2,2)\n",
        "\n",
        "3. **Convolutional Layer 2**\n",
        "   - Filters: 32\n",
        "   - Kernel size: (3,3)\n",
        "   - Activation: ReLU\n",
        "\n",
        "4. **MaxPooling Layer 2**\n",
        "   - Pool size: (2,2)\n",
        "\n",
        "5. **Flatten Layer**\n",
        "   - Converts 2D feature maps into 1D feature vectors.\n",
        "\n",
        "6. **Fully Connected (Dense) Layer**\n",
        "   - Units: 128\n",
        "   - Activation: ReLU\n",
        "\n",
        "7. **Output Layer**\n",
        "   - Units: 1\n",
        "   - Activation: Sigmoid (used for binary classification)\n",
        "\n",
        "Model summary:\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Model Compilation**\n",
        "\n",
        "The model is compiled using:\n",
        "\n",
        "- **Optimizer**: Adam\n",
        "- **Loss Function**: Binary Crossentropy\n",
        "- **Metrics**: Accuracy\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Model Training**\n",
        "\n",
        "The model is trained using the `fit` method:\n",
        "\n",
        "```python\n",
        "model.fit(train_set, epochs=10, validation_data=test_set)\n",
        "```\n",
        "\n",
        "- **Epochs**: 10\n",
        "- **Training set**: Provided through `train_set`\n",
        "- **Validation set**: Provided through `test_set`\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Model Evaluation and Accuracy**\n",
        "\n",
        "The training and validation accuracy and loss are printed out after each epoch. A performance curve would usually be plotted to show training vs. validation accuracy and loss over epochs, although the plot isn't included in the notebook.\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Making Predictions**\n",
        "\n",
        "The model is tested on a new image using the following steps:\n",
        "\n",
        "- Image is loaded and resized to 64x64.\n",
        "- Converted to an array and expanded in dimension to match input shape.\n",
        "- Prediction is made and class label is printed.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('single_prediction/image.jpg', target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "result = model.predict(test_image)\n",
        "train_set.class_indices\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'class_1'\n",
        "else:\n",
        "    prediction = 'class_0'\n",
        "\n",
        "print(prediction)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **10. Conclusion**\n",
        "\n",
        "The CNN model was successfully implemented for binary image classification. Key steps included data preprocessing, model construction, training, evaluation, and prediction. The model can be further enhanced by:\n",
        "\n",
        "- Adding more convolutional layers.\n",
        "- Using data augmentation to reduce overfitting.\n",
        "- Experimenting with different optimizers and learning rates.\n",
        "- Plotting training and validation curves for better visual analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### **11. Future Scope**\n",
        "\n",
        "- **Multi-class Classification**: Extend the model to handle more than two categories using `categorical` class mode and `softmax` activation in the output layer.\n",
        "- **Transfer Learning**: Use pre-trained models like VGG16 or ResNet to improve accuracy.\n",
        "- **Model Deployment**: Create a web or mobile application interface for real-time predictions.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bjz8_SiongFS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmbGW9VYohIO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
